{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b869db79a8e2b860",
   "metadata": {},
   "source": [
    "# Exercise 3: Intro to text generation\n",
    "\n",
    "This exercise demonstrates the power and flexibility of text generation. By the end of the exercise, you will have learned to:\n",
    "- Use LLMs for zero-shot text classification\n",
    "- Use one of the best open LLMs as synthetic participants in psychological experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec251e1c2719b28",
   "metadata": {},
   "source": [
    "## Environment Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    # Mount google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Installing requisite packages\n",
    "    !pip install --upgrade transformers openai  &> /dev/null\n",
    "\n",
    "    # Change working directory \n",
    "    %cd /content/drive/MyDrive/LLM4Psych_DGPS2024/exercise_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2948ad848d628827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:17:45.875249Z",
     "start_time": "2024-09-10T14:17:45.680357Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from huggingface_hub import InferenceClient\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be1767",
   "metadata": {},
   "source": [
    "Get API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a9cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming 'src' is one level down (in the current directory or a subdirectory)\n",
    "path_to_src = os.path.join('..','src')  # Moves one level down to 'src' folder\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(path_to_src)\n",
    "\n",
    "# Now you can import your API_key module\n",
    "import API_key as key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e83d6d0c68d78",
   "metadata": {},
   "source": [
    "## Zero-shot Classification: Media Bias\n",
    "The goal of this section will be to classify tweets as either `\"neutral\"` or `\"partisan\"`. We will make use of a [dataset](https://data.world/crowdflower/classification-of-pol-social) of tweets containing four columns:\n",
    "\n",
    "1. `\"author\"`: The author of the tweet.\n",
    "2. `\"text\"`: The text of the tweet.\n",
    "3. `\"bias\"`:  The political bias of the tweet. This can be either `\"neutral\"` or `\"partisan\"`. The number of neutral and partisan tweets is intentionally equal in the dataset.\n",
    "4. `\"type\"`:  The type of tweet.\n",
    "\n",
    "We begin by loading the dataset as a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b943e40b73abab85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:17:45.893126Z",
     "start_time": "2024-09-10T14:17:45.876082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>bias</th>\n",
       "      <th>type</th>\n",
       "      <th>audience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dina Titus (Representative from Nevada)</td>\n",
       "      <td>#FMLA has been helping families for 20 years, ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>support</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tim Griffin (Representative from Arkansas)</td>\n",
       "      <td>Join me for another \"#SweetTea with Tim\" in #S...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>media</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Grayson (Representative from Florida)</td>\n",
       "      <td>The Original Chickenhawk. http://t.co/gqThSecLxB</td>\n",
       "      <td>neutral</td>\n",
       "      <td>policy</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michelle Lujan Grisham (Representative from Ne...</td>\n",
       "      <td>Like my @facebook page for updates on how I'm ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mobilization</td>\n",
       "      <td>constituency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dean Heller (Senator from Nevada)</td>\n",
       "      <td>@NevadaWolfPack's own @Kaepernick7 = Best Brea...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>personal</td>\n",
       "      <td>constituency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Andy Harris (Representative from Maryland)</td>\n",
       "      <td>13k plans at risk RT @ReutersUS: Aetna exits O...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>information</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Doug Collins (Representative from Georgia)</td>\n",
       "      <td>Targeting conservatives by day, partying by ni...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>David Schweikert (Representative from Arizona)</td>\n",
       "      <td>Great talk earlier tonight w/@TheKudlowReport....</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Joe Barton (Representative from Texas)</td>\n",
       "      <td>President calls for \"modern pipelines.\" What a...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>attack</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ann Kuster (Representative from New Hampshire)</td>\n",
       "      <td>Met w/ the #NH Manufacturing Extension Partner...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>constituency</td>\n",
       "      <td>constituency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               author  \\\n",
       "0             Dina Titus (Representative from Nevada)   \n",
       "1          Tim Griffin (Representative from Arkansas)   \n",
       "2          Alan Grayson (Representative from Florida)   \n",
       "3   Michelle Lujan Grisham (Representative from Ne...   \n",
       "4                   Dean Heller (Senator from Nevada)   \n",
       "..                                                ...   \n",
       "95         Andy Harris (Representative from Maryland)   \n",
       "96         Doug Collins (Representative from Georgia)   \n",
       "97     David Schweikert (Representative from Arizona)   \n",
       "98             Joe Barton (Representative from Texas)   \n",
       "99     Ann Kuster (Representative from New Hampshire)   \n",
       "\n",
       "                                                 text      bias          type  \\\n",
       "0   #FMLA has been helping families for 20 years, ...   neutral       support   \n",
       "1   Join me for another \"#SweetTea with Tim\" in #S...   neutral         media   \n",
       "2    The Original Chickenhawk. http://t.co/gqThSecLxB   neutral        policy   \n",
       "3   Like my @facebook page for updates on how I'm ...   neutral  mobilization   \n",
       "4   @NevadaWolfPack's own @Kaepernick7 = Best Brea...   neutral      personal   \n",
       "..                                                ...       ...           ...   \n",
       "95  13k plans at risk RT @ReutersUS: Aetna exits O...  partisan   information   \n",
       "96  Targeting conservatives by day, partying by ni...  partisan        policy   \n",
       "97  Great talk earlier tonight w/@TheKudlowReport....  partisan        policy   \n",
       "98  President calls for \"modern pipelines.\" What a...  partisan        attack   \n",
       "99  Met w/ the #NH Manufacturing Extension Partner...  partisan  constituency   \n",
       "\n",
       "        audience  \n",
       "0       national  \n",
       "1       national  \n",
       "2       national  \n",
       "3   constituency  \n",
       "4   constituency  \n",
       "..           ...  \n",
       "95      national  \n",
       "96      national  \n",
       "97      national  \n",
       "98      national  \n",
       "99  constituency  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_bias = pd.read_csv('media_bias.csv')\n",
    "media_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f61741148117d",
   "metadata": {},
   "source": [
    "The code next initializes the `InferenceClient` with an access token, **which you will need to replace with your own [access token](https://huggingface.co/settings/tokens)** (access tokens start with 'hf_...'). It then loops through the tweets in the `media_bias` dataframe. The code then generates the output using the `chat_completion` method of the `InferenceClient` class. This allows us to play around with certain generation-related parameters such as `max_tokens` and `temperature`. \n",
    "\n",
    "The output is then parsed to extract the label, which is then appended to the `zero_shot_labels` list. The code then adds the `zero_shot_labels` list to the `media_bias` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf9f91c8f9b6e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa72d4cf2214df99574a6e650fc1e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>bias</th>\n",
       "      <th>type</th>\n",
       "      <th>audience</th>\n",
       "      <th>zero_shot_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dina Titus (Representative from Nevada)</td>\n",
       "      <td>#FMLA has been helping families for 20 years, ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>support</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tim Griffin (Representative from Arkansas)</td>\n",
       "      <td>Join me for another \"#SweetTea with Tim\" in #S...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>media</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Grayson (Representative from Florida)</td>\n",
       "      <td>The Original Chickenhawk. http://t.co/gqThSecLxB</td>\n",
       "      <td>neutral</td>\n",
       "      <td>policy</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michelle Lujan Grisham (Representative from Ne...</td>\n",
       "      <td>Like my @facebook page for updates on how I'm ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mobilization</td>\n",
       "      <td>constituency</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dean Heller (Senator from Nevada)</td>\n",
       "      <td>@NevadaWolfPack's own @Kaepernick7 = Best Brea...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>personal</td>\n",
       "      <td>constituency</td>\n",
       "      <td>partisan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Andy Harris (Representative from Maryland)</td>\n",
       "      <td>13k plans at risk RT @ReutersUS: Aetna exits O...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>information</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Doug Collins (Representative from Georgia)</td>\n",
       "      <td>Targeting conservatives by day, partying by ni...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>David Schweikert (Representative from Arizona)</td>\n",
       "      <td>Great talk earlier tonight w/@TheKudlowReport....</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Joe Barton (Representative from Texas)</td>\n",
       "      <td>President calls for \"modern pipelines.\" What a...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>attack</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ann Kuster (Representative from New Hampshire)</td>\n",
       "      <td>Met w/ the #NH Manufacturing Extension Partner...</td>\n",
       "      <td>partisan</td>\n",
       "      <td>constituency</td>\n",
       "      <td>constituency</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               author  \\\n",
       "0             Dina Titus (Representative from Nevada)   \n",
       "1          Tim Griffin (Representative from Arkansas)   \n",
       "2          Alan Grayson (Representative from Florida)   \n",
       "3   Michelle Lujan Grisham (Representative from Ne...   \n",
       "4                   Dean Heller (Senator from Nevada)   \n",
       "..                                                ...   \n",
       "95         Andy Harris (Representative from Maryland)   \n",
       "96         Doug Collins (Representative from Georgia)   \n",
       "97     David Schweikert (Representative from Arizona)   \n",
       "98             Joe Barton (Representative from Texas)   \n",
       "99     Ann Kuster (Representative from New Hampshire)   \n",
       "\n",
       "                                                 text      bias          type  \\\n",
       "0   #FMLA has been helping families for 20 years, ...   neutral       support   \n",
       "1   Join me for another \"#SweetTea with Tim\" in #S...   neutral         media   \n",
       "2    The Original Chickenhawk. http://t.co/gqThSecLxB   neutral        policy   \n",
       "3   Like my @facebook page for updates on how I'm ...   neutral  mobilization   \n",
       "4   @NevadaWolfPack's own @Kaepernick7 = Best Brea...   neutral      personal   \n",
       "..                                                ...       ...           ...   \n",
       "95  13k plans at risk RT @ReutersUS: Aetna exits O...  partisan   information   \n",
       "96  Targeting conservatives by day, partying by ni...  partisan        policy   \n",
       "97  Great talk earlier tonight w/@TheKudlowReport....  partisan        policy   \n",
       "98  President calls for \"modern pipelines.\" What a...  partisan        attack   \n",
       "99  Met w/ the #NH Manufacturing Extension Partner...  partisan  constituency   \n",
       "\n",
       "        audience zero_shot_label  \n",
       "0       national         neutral  \n",
       "1       national         neutral  \n",
       "2       national        partisan  \n",
       "3   constituency         neutral  \n",
       "4   constituency        partisan  \n",
       "..           ...             ...  \n",
       "95      national         neutral  \n",
       "96      national        partisan  \n",
       "97      national         neutral  \n",
       "98      national        partisan  \n",
       "99  constituency         neutral  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize client\n",
    "# api_key = '<access_token_here>' \n",
    "client = InferenceClient(token=key.hugging_api_key_read)\n",
    "\n",
    "# Zero-shot classification prompt\n",
    "zero_shot_prompt = \"Is this text neutral or partisan? Strictly answer with only 'neutral' or 'partisan':\\n\"\n",
    "\n",
    "zero_shot_labels = []\n",
    "for tweet in tqdm(media_bias['text']):    \n",
    "    \n",
    "    # Zero-shot classification \n",
    "    output = client.chat_completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": zero_shot_prompt + tweet}\n",
    "        ],\n",
    "        model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        max_tokens=50,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    # Accessing the text output and lowercasing it\n",
    "    output = output.choices[0].message.content.lower()\n",
    "    \n",
    "    # Extract label and append to list\n",
    "    label = 'neutral' if 'neutral' in output else 'partisan' if 'partisan' in output else 'nan' # \n",
    "    zero_shot_labels.append(label)\n",
    "\n",
    "# Add zero-shot labels to dataframe\n",
    "media_bias['zero_shot_label'] = zero_shot_labels\n",
    "media_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1566347fad5c0d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Comparing zero-shot and actual labels\n",
    "print(f'Zero-shot accuracy: {(media_bias[\"zero_shot_label\"] == media_bias[\"bias\"]).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763143303054bc36",
   "metadata": {},
   "source": [
    "Impressively, without any task-specific training, the model achieves an accuracy of 72%. This compares to a baseline accuracy of 50% that could be achieved by randomly guessing between the two classes.\n",
    "\n",
    "The results can also be visualized with a confusion matrix, which shows the number of true positives, true negatives, false positives, and false negatives. The confusion matrix can be used to identify where the model is making mistakes and to understand the types of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a14100899bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='zero_shot_label', ylabel='bias'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion = pd.crosstab(media_bias['bias'], media_bias['zero_shot_label'])\n",
    "sns.heatmap(confusion, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095b45c98303886",
   "metadata": {},
   "source": [
    "As you can see, the model might have a slight bias towards classifying tweets as partisan, leading to a higher number of false postives than false negatives.\n",
    "\n",
    "**TASK 1**: Try playing around with the system prompt to give it different roles. Can you find one that increases the accuracy of Llama 3? (e.g. `\"You are a thoughtful political scientist who accurately distinguishes neutral and partisan messages\"`).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fa1e8bebb0454",
   "metadata": {},
   "source": [
    "## Synthetic Participants: The Berlin Numeracy Test\n",
    "In this section, we will explore the usage of causal LLMs as synthetic participants in a psychological experiment. We will this time use the 70B parameter version of Llama 3 to solve the [Berlin Numeracy Test](https://doi.org/10.1017/S1930297500001819). This is a widely used test to measure an individual's ability to understand and apply statistical concepts. \n",
    "\n",
    "The test consists of four questions that require a basic understanding of probability and statistics. In this exercise, we will ask Llama 3 to solve these questions. Llama 3 will provide an answer to each question, and we will evaluate the quality of the response.\n",
    "\n",
    "The code begins by defining the four questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b04f4177d7b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"\"\"\n",
    "Imagine we are throwing a five-sided die 50 times. On average, out of these 50 throws how many times would this five-sided die show an odd number (1, 3 or 5)?\n",
    "\"\"\"\n",
    "\n",
    "q2 = \"\"\"\n",
    "Out of 1,000 people in a small town 500 are members of a choir. Out of these 500 members in the choir 100 are men. Out of the 500 inhabitants that are not in the choir 300 are men. What is the probability that a randomly drawn man is a member of the choir? (please indicate the probability in percent).\n",
    "\"\"\"\n",
    "\n",
    "q3 = \"\"\"\n",
    "Imagine we are throwing a loaded die (6 sides). The probability that the die shows a 6 is twice as high as the probability of each of the other numbers. On average, out of these 70 throws, how many times would the die show the number 6?\n",
    "\"\"\"\n",
    "\n",
    "q4 = \"\"\"\n",
    "In a forest 20% of mushrooms are red, 50% brown and 30% white. A red mushroom is poisonous with a probability of 20%. A mushroom that is not red is poisonous with a probability of 5%. What is the probability that a poisonous mushroom in the forest is red?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd80d5db76dc8",
   "metadata": {},
   "source": [
    "The code next initializes the `InferenceClient` with an access token. Since we are now using Llama-3.1 (not free on HF), **you will need to replace the `api_key` with the HF Pro token we sent you**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c9c283b1ebabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": " (Request ID: IShTDX6R4vQoT6Cw13cv3)\n\nBad request:\nModel requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Add additional instruction to the question\u001b[39;00m\n\u001b[0;32m      9\u001b[0m question \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124mReturn your answer immediately with no working, then explain your answer.\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mAdd ** around your final answer to make it more visible.\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat_completion(\n\u001b[0;32m     15\u001b[0m messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     16\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an average participant in a psychology experiment.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     17\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: question}\n\u001b[0;32m     18\u001b[0m ],\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     21\u001b[0m temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Accessing the text output \u001b[39;00m\n\u001b[0;32m     25\u001b[0m response \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:770\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[1;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p)\u001b[0m\n\u001b[0;32m    764\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are not supported by the model. This is due to the model not been served by a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText-Generation-Inference server. The provided tool parameters will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# generate response\u001b[39;00m\n\u001b[1;32m--> 770\u001b[0m text_generation_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_generation(\n\u001b[0;32m    771\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mmessages,  \u001b[38;5;66;03m# type: ignore # Not correct type but works implicitly\u001b[39;00m\n\u001b[0;32m    772\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    773\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    774\u001b[0m     details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    775\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[0;32m    776\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    777\u001b[0m     stop_sequences\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    778\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    779\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m    780\u001b[0m )\n\u001b[0;32m    782\u001b[0m \u001b[38;5;66;03m# Format as a ChatCompletionOutput with dummy values for fields we can't provide\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ChatCompletionOutput(\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    785\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    799\u001b[0m     ],\n\u001b[0;32m    800\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:2061\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[1;34m(self, prompt, details, stream, model, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[0;32m   2037\u001b[0m         _set_unsupported_text_generation_kwargs(model, unused_params)\n\u001b[0;32m   2038\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_generation(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2039\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m   2040\u001b[0m             details\u001b[38;5;241m=\u001b[39mdetails,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2059\u001b[0m             watermark\u001b[38;5;241m=\u001b[39mwatermark,\n\u001b[0;32m   2060\u001b[0m         )\n\u001b[1;32m-> 2061\u001b[0m     raise_text_generation_error(e)\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;66;03m# Parse output\u001b[39;00m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\inference\\_common.py:460\u001b[0m, in \u001b[0;36mraise_text_generation_error\u001b[1;34m(http_error)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttp_error\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;66;03m# Otherwise, fallback to default error\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m http_error\n",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:2032\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[1;34m(self, prompt, details, stream, model, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2032\u001b[0m     bytes_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost(json\u001b[38;5;241m=\u001b[39mpayload, model\u001b[38;5;241m=\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, stream\u001b[38;5;241m=\u001b[39mstream)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2034\u001b[0m     match \u001b[38;5;241m=\u001b[39m MODEL_KWARGS_NOT_USED_REGEX\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:273\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     hf_raise_for_status(response)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32mc:\\Users\\fenn\\AppData\\Local\\R-MINI~1\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m     )\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n",
      "\u001b[1;31mBadRequestError\u001b[0m:  (Request ID: IShTDX6R4vQoT6Cw13cv3)\n\nBad request:\nModel requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query."
     ]
    }
   ],
   "source": [
    "# api_key = '<pro_token_here>' \n",
    "client = InferenceClient(token=key.hugging_api_key_read)\n",
    "\n",
    "# Loop through questions and generate responses\n",
    "for i, question in enumerate([q1, q2, q3, q4]):\n",
    "    print('-------------------------')   \n",
    "    \n",
    "    # Add additional instruction to the question\n",
    "    question += \"\"\"\n",
    "    Return your answer immediately with no working, then explain your answer.\n",
    "    Add ** around your final answer to make it more visible.\n",
    "     \"\"\"\n",
    "    \n",
    "    output = client.chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an average participant in a psychology experiment.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0\n",
    "    )\n",
    "    \n",
    "    # Accessing the text output \n",
    "    response = output.choices[0].message.content\n",
    "    \n",
    "    # Format question and response for printing\n",
    "    question = '\\n'.join(textwrap.wrap(question, 100))\n",
    "    response = '\\n'.join(textwrap.wrap(response, 100))\n",
    "    print(f\"Question {i+1}: {question} \\n\\nAnswer: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97094deb99953c0",
   "metadata": {},
   "source": [
    "The correct answers are 30, 25, 20, and 50, meaning the model only got 0/4 questions correct (with the current prompting strategy...). \n",
    "\n",
    "**TASK 1**: Change the `temperature` value to `1.0`, `3.0`. What impact does temperature have on the responses?<br>\n",
    "**TASK 2**: Change the `temperature` back to `0.0`. Now remove the instruction to `\"Return your answer immediately with no working, then explain your answer.\"` and replace it with a *chain-of-thought* prompt instructing the model to `\"Go through your reasoning step by step before giving the final answer.\"`. Why do you think this might improve the quality of the responses?<br>\n",
    "**TASK 3**: Try changing the `model` to `\"meta-llama/Meta-Llama-3.1-70B-Instruct\"`. Does the larger model do any better?<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
